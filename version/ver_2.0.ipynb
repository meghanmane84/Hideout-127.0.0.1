{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MybG5OIVxcC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5cba0a9-213c-4c9a-91f1-9eb615061a49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU is available: \", tf.config.list_physical_devices('GPU'))\n"
      ],
      "metadata": {
        "id": "uTNMVtFzblqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c47fe4e0-3d99-4c63-de5c-aa5476c9081c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "L5_wdK7OfXQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_path=\"/content/sample\"\n",
        "main_path = \"/content/drive/MyDrive/SKYSAT_Dataset\""
      ],
      "metadata": {
        "id": "aFVdD6-3lnbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# List the image files in the directory\n",
        "image_files = [file for file in os.listdir(main_path) if file.endswith('.jpg')]\n",
        "\n",
        "# Create an empty list to store pixel data and timestamps\n",
        "pixel_data = []\n",
        "timestamps = []\n",
        "\n",
        "for image_file in image_files:\n",
        "    # image_path = os.path.join(main_path, image_file)\n",
        "    # image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "    print(image_file)"
      ],
      "metadata": {
        "id": "MdOjKKBmSxPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "\n",
        "# image_folders = [file for file in os.listdir(main_path)]\n",
        "# for image_folder in image_folders:\n",
        "#   folder_path = os.path.join(main_path, image_folder)\n",
        "#   image_files = [file for file in os.listdir(folder_path) if file.endswith('.jpg')]\n",
        "#   print(folder_path)\n",
        "\n",
        "#   # Create an empty list to store pixel data and timestamps\n",
        "#   pixel_data = []\n",
        "#   timestamps = []\n",
        "\n",
        "#   # Iterate through the image files, read each image, resize to target size, and flatten as 1D array\n",
        "#   for image_file in image_files:\n",
        "#       image_path = os.path.join(folder_path, image_file)\n",
        "#       print(image_path)\n",
        "#       image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)  # Load image with alpha channel\n",
        "\n",
        "#       # Extract the timestamp from the image filename (assuming the format is \"YYYYMMDD_HHMM.jpg\")\n",
        "#       filename_without_extension = os.path.splitext(image_file)[0]\n",
        "#       timestamp = filename_without_extension  # Use the entire filename as the timestamp\n",
        "\n",
        "#       # Resize the image to the target size (256x256)\n",
        "#       target_size = (256, 256)\n",
        "#       resized_image = cv2.resize(image, target_size)\n",
        "\n",
        "#       # Flatten the 2D array to 1D and normalize pixel values by dividing by 255\n",
        "#       flattened_pixels = (resized_image.astype(np.float32) / 255.0).flatten()\n",
        "\n",
        "#       # Append the flattened pixels and timestamp to their respective lists\n",
        "#       pixel_data.append(flattened_pixels)\n",
        "#       timestamps.append(timestamp)\n",
        "\n",
        "#   # Create a Pandas DataFrame from the pixel data and timestamps\n",
        "# df = pd.DataFrame(pixel_data)\n",
        "\n",
        "# # Convert the timestamps to datetime objects and set them as the index\n",
        "# df.index = pd.to_datetime(timestamps, format='%Y%m%d_%H%M')\n",
        "\n",
        "# # Save the DataFrame as a CSV file\n",
        "# csv_path = \"/content/drive/MyDrive/main_image_data_with_timestamps.csv\"\n",
        "# df.to_csv(csv_path)\n",
        "\n",
        "# # Print the path to the saved CSV file\n",
        "# csv_path\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Define the main path where image folders are located\n",
        "\n",
        "# Function to extract pixels and timestamps from image files\n",
        "def process_image(image_path):\n",
        "    # Load image with alpha channel\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "    # Resize the image to the target size (256x256)\n",
        "    target_size = (256, 256)\n",
        "    resized_image = cv2.resize(image, target_size)\n",
        "    # Flatten the 2D array to 1D and normalize pixel values by dividing by 255\n",
        "    flattened_pixels = (resized_image.astype(np.float32) / 255.0).flatten()\n",
        "    # Extract the timestamp from the image filename (assuming the format is \"YYYYMMDD_HHMM.jpg\")\n",
        "    filename_without_extension = os.path.splitext(os.path.basename(image_path))[0]\n",
        "    timestamp = filename_without_extension  # Use the entire filename as the timestamp\n",
        "    return flattened_pixels, timestamp\n",
        "\n",
        "# Iterate through image folders\n",
        "for image_folder in os.listdir(main_path):\n",
        "    folder_path = os.path.join(main_path, image_folder)\n",
        "    if not os.path.isdir(folder_path):\n",
        "        continue\n",
        "\n",
        "    print(folder_path)\n",
        "    pixel_data = []  # List to store pixel data\n",
        "    timestamps = []  # List to store timestamps\n",
        "\n",
        "    # Iterate through image files in the folder\n",
        "    for image_file in os.listdir(folder_path):\n",
        "        if not image_file.endswith('.jpg'):\n",
        "            continue\n",
        "\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        print(image_path)\n",
        "\n",
        "        flattened_pixels, timestamp = process_image(image_path)\n",
        "        pixel_data.append(flattened_pixels)\n",
        "        timestamps.append(timestamp)\n",
        "\n",
        "    # Create a DataFrame from the pixel data and timestamps\n",
        "    df = pd.DataFrame(pixel_data, index=pd.to_datetime(timestamps, format='%Y%m%d_%H%M'))\n",
        "\n",
        "    # Save the DataFrame as a CSV file for each folder\n",
        "    csv_filename = f\"{image_folder}_image_data_with_timestamps.csv\"\n",
        "    csv_path = os.path.join(main_path, csv_filename)\n",
        "    df.to_csv(csv_path)\n",
        "    print(f\"CSV saved to: {csv_path}\")\n"
      ],
      "metadata": {
        "id": "U3hNaK47VlMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Define the main path where image folders are located\n",
        "main_path = \"/content/drive/MyDrive/SKYSAT_Dataset\"\n",
        "\n",
        "# Function to extract pixels and timestamps from image files\n",
        "def process_image(image_path):\n",
        "    # Load image with alpha channel\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "    if image is None:\n",
        "        return None, None\n",
        "\n",
        "    # Resize the image to the target size (256x256)\n",
        "    target_size = (256, 256)\n",
        "    resized_image = cv2.resize(image, target_size)\n",
        "    # Flatten the 2D array to 1D and normalize pixel values by dividing by 255\n",
        "    flattened_pixels = (resized_image.astype(np.float32) / 255.0).flatten()\n",
        "    # Extract the timestamp from the image filename (assuming the format is \"YYYYMMDD_HHMM.jpg\")\n",
        "    filename_without_extension = os.path.splitext(os.path.basename(image_path))[0]\n",
        "    timestamp = filename_without_extension  # Use the entire filename as the timestamp\n",
        "    return flattened_pixels, timestamp\n",
        "\n",
        "# Get a list of days for which CSV files already exist\n",
        "existing_days = set()\n",
        "for file in os.listdir(main_path):\n",
        "    if file.endswith('.csv'):\n",
        "        day = file.split('_')[0]\n",
        "        existing_days.add(day)\n",
        "\n",
        "# Iterate through image folders\n",
        "for image_folder in sorted(os.listdir(main_path)):\n",
        "    folder_path = os.path.join(main_path, image_folder)\n",
        "    if not os.path.isdir(folder_path):\n",
        "        continue\n",
        "\n",
        "    # Check if a CSV file for this day already exists, if yes, skip\n",
        "    if image_folder in existing_days:\n",
        "        print(f\"CSV file already exists for {image_folder}. Skipping...\")\n",
        "        continue\n",
        "\n",
        "    print(folder_path)\n",
        "    pixel_data = []  # List to store pixel data\n",
        "    timestamps = []  # List to store timestamps\n",
        "\n",
        "    # Iterate through image files in the folder\n",
        "    for image_file in sorted(os.listdir(folder_path)):\n",
        "        if not image_file.endswith('.jpg'):\n",
        "            continue\n",
        "\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        print(image_path)\n",
        "\n",
        "        flattened_pixels, timestamp = process_image(image_path)\n",
        "        if flattened_pixels is None or timestamp is None:\n",
        "            continue\n",
        "\n",
        "        pixel_data.append(flattened_pixels)\n",
        "        timestamps.append(timestamp)\n",
        "\n",
        "    # Create a DataFrame from the pixel data and timestamps\n",
        "    df = pd.DataFrame(pixel_data, index=pd.to_datetime(timestamps, format='%Y%m%d_%H%M'))\n",
        "\n",
        "    # Save the DataFrame as a CSV file for each folder\n",
        "    csv_filename = f\"{image_folder}_image_data_with_timestamps.csv\"\n",
        "    csv_path = os.path.join(main_path, csv_filename)\n",
        "    df.to_csv(csv_path)\n",
        "    print(f\"CSV saved to: {csv_path}\")\n"
      ],
      "metadata": {
        "id": "CNlk14xAwnYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# List the image files in the directory\n",
        "image_files = [file for file in os.listdir(main_path) if file.endswith('.jpg')]\n",
        "\n",
        "# Create an empty list to store pixel data and timestamps\n",
        "pixel_data = []\n",
        "timestamps = []\n",
        "\n",
        "# Iterate through the image files, read each image, resize to target size, and flatten as 1D array\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(main_path, image_file)\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)  # Load image with alpha channel\n",
        "\n",
        "    # Extract the timestamp from the image filename (assuming the format is \"YYYYMMDD_HHMM.jpg\")\n",
        "    filename_without_extension = os.path.splitext(image_file)[0]\n",
        "    timestamp = filename_without_extension  # Use the entire filename as the timestamp\n",
        "\n",
        "    # Resize the image to the target size (256x256)\n",
        "    target_size = (256, 256)\n",
        "    resized_image = cv2.resize(image, target_size)\n",
        "\n",
        "    # Flatten the 2D array to 1D and normalize pixel values by dividing by 255\n",
        "    flattened_pixels = (resized_image.astype(np.float32) / 255.0).flatten()\n",
        "\n",
        "    # Append the flattened pixels and timestamp to their respective lists\n",
        "    pixel_data.append(flattened_pixels)\n",
        "    timestamps.append(timestamp)\n",
        "\n",
        "# Create a Pandas DataFrame from the pixel data and timestamps\n",
        "df = pd.DataFrame(pixel_data)\n",
        "\n",
        "# Convert the timestamps to datetime objects and set them as the index\n",
        "df.index = pd.to_datetime(timestamps, format='%Y%m%d_%H%M')\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "csv_path = \"/content/main_image_data_with_timestamps.csv\"\n",
        "df.to_csv(csv_path)\n",
        "\n",
        "# Print the path to the saved CSV file\n",
        "csv_path"
      ],
      "metadata": {
        "id": "ql3r9KGaQsoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List the image files in the directory\n",
        "image_files = [file for file in os.listdir(sample_path) if file.endswith('.jpg')]\n",
        "\n",
        "# Create an empty list to store pixel data and timestamps\n",
        "pixel_data = []\n",
        "timestamps = []\n",
        "\n",
        "# Iterate through the image files, read each image, resize to target size, and flatten as 1D array\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(sample_path, image_file)\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)  # Load image with alpha channel\n",
        "\n",
        "    # Extract the timestamp from the image filename (assuming the format is \"YYYYMMDD_HHMM.jpg\")\n",
        "    filename_without_extension = os.path.splitext(image_file)[0]\n",
        "    timestamp = filename_without_extension  # Use the entire filename as the timestamp\n",
        "\n",
        "    # Resize the image to the target size (256x256)\n",
        "    target_size = (256, 256)\n",
        "    resized_image = cv2.resize(image, target_size)\n",
        "\n",
        "    # Flatten the 2D array to 1D and normalize pixel values by dividing by 255\n",
        "    flattened_pixels = (resized_image.astype(np.float32) / 255.0).flatten()\n",
        "\n",
        "    # Append the flattened pixels and timestamp to their respective lists\n",
        "    pixel_data.append(flattened_pixels)\n",
        "    timestamps.append(timestamp)\n",
        "\n",
        "# Create a Pandas DataFrame from the pixel data and timestamps\n",
        "df = pd.DataFrame(pixel_data)\n",
        "\n",
        "# Convert the timestamps to datetime objects and set them as the index\n",
        "df.index = pd.to_datetime(timestamps, format='%Y%m%d_%H%M')\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "csv_path = \"/content/sample_image_data_with_timestamps.csv\"\n",
        "df.to_csv(csv_path)\n",
        "\n",
        "# Print the path to the saved CSV file\n",
        "csv_path"
      ],
      "metadata": {
        "id": "sUOQfrYouns_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/My Drive/'\n",
        "os.chdir(data_dir)"
      ],
      "metadata": {
        "id": "n2691FhXvIYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "vzdy3DMUvcvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# Define the number of random images to display\n",
        "num_images_to_display = 5  # You can change this number as needed\n",
        "\n",
        "# Get a random sample of timestamps\n",
        "random_timestamps = random.sample(list(df.index), num_images_to_display)\n",
        "\n",
        "# Plot and display the random images\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, timestamp in enumerate(random_timestamps):\n",
        "    plt.subplot(1, num_images_to_display, i + 1)\n",
        "    image_data = df.loc[timestamp].values.reshape(256, 256, -1)  # Reshape to 256x256x4 (RGBA)\n",
        "    image_data = (image_data * 255).astype(np.uint8)  # Convert back to uint8\n",
        "    plt.imshow(cv2.cvtColor(image_data, cv2.COLOR_RGBA2RGB))  # Convert RGBA to RGB\n",
        "    plt.title(timestamp)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eDJ59R4NvflA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load your dataset\n",
        "# Assuming df is the DataFrame that you have loaded with the data you showed.\n",
        "# df = pd.read_csv('your_file.csv', index_col=0)\n",
        "\n",
        "# Now let's reshape the data back into image format assuming the images are grayscale\n",
        "# If they are color, you would need to divide the number of columns by 3 and stack the channels accordingly\n",
        "image_width = image_height = int((df.shape[1] // 3) ** 0.5)  # example for square RGB images\n",
        "images = df.values.reshape(-1, image_width, image_height, 3)\n",
        "\n",
        "# Split the data into training and validation sets (e.g., 80-20 split)\n",
        "X_train, X_val = train_test_split(images, test_size=0.2, random_state=42)\n",
        "\n",
        "# X_train now contains your training images, and X_val contains your validation images.\n"
      ],
      "metadata": {
        "id": "V-A4Cz1aEw0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.backend import clear_session\n",
        "clear_session()\n",
        "\n"
      ],
      "metadata": {
        "id": "fUpusH5aHckM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.layers import Input, Dense, Reshape, Flatten\n",
        "from keras.layers import BatchNormalization, LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Set the image dimensions and latent dimension\n",
        "img_rows = 256\n",
        "img_cols = 256\n",
        "channels = 3\n",
        "img_shape = (img_rows, img_cols, channels)\n",
        "latent_dim = 1000\n",
        "\n",
        "# Build and compile the discriminator\n",
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=img_shape))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.summary()\n",
        "    img = Input(shape=img_shape)\n",
        "    validity = model(img)\n",
        "    return Model(img, validity)\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
        "\n",
        "# Build the generator\n",
        "def build_generator():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, input_dim=latent_dim))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(np.prod(img_shape), activation='tanh'))\n",
        "    model.add(Reshape(img_shape))\n",
        "    model.summary()\n",
        "    noise = Input(shape=(latent_dim,))\n",
        "    img = model(noise)\n",
        "    return Model(noise, img)\n",
        "\n",
        "# The generator takes noise as input and generates images\n",
        "z = Input(shape=(latent_dim,))\n",
        "generator = build_generator()\n",
        "img = generator(z)\n",
        "\n",
        "# Now build the optimizer with the combined model's variables\n",
        "optimizer = Adam(0.0002, 0.5)\n",
        "optimizer.build(generator.trainable_variables)\n",
        "\n",
        "# Build and compile the combined model\n",
        "valid = discriminator(img)\n",
        "discriminator.trainable = False  # Ensure this is done before the combined model is compiled\n",
        "combined = Model(z, valid)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "# Training hyperparameters\n",
        "epochs = 10000\n",
        "batch_size = 32\n",
        "sample_interval = 200\n",
        "\n",
        "# Adversarial ground truths\n",
        "valid = np.ones((batch_size, 1))\n",
        "fake = np.zeros((batch_size, 1))\n",
        "\n"
      ],
      "metadata": {
        "id": "SyQMHhIuKD2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    # ---------------------\n",
        "    #  Train Discriminator\n",
        "    # ---------------------\n",
        "\n",
        "    # Select a random batch of images\n",
        "    idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "    imgs = X_train[idx]\n",
        "\n",
        "    # Sample noise and generate a batch of new images\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "\n",
        "    # Train the discriminator (real classified as ones and generated as zeros)\n",
        "    d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
        "    d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    # ---------------------\n",
        "    #  Train Generator\n",
        "    # ---------------------\n",
        "\n",
        "    # Sample noise and generate a batch of new images\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "\n",
        "    # The generator wants the discriminator to label the generated samples as valid\n",
        "    g_loss = combined.train_on_batch(noise, valid)\n",
        "\n",
        "    # Print the progress\n",
        "    print(f\"{epoch} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]:.2f}%] [G loss: {g_loss}]\")\n",
        "\n",
        "    # If at save interval => save generated image samples and perform validation\n",
        "    if epoch % sample_interval == 0:\n",
        "        # Save generated images for validation purposes\n",
        "        # save_images(epoch, generator)\n",
        "\n",
        "        # Evaluate discriminator performance on the validation set\n",
        "        idx = np.random.randint(0, X_val.shape[0], batch_size)\n",
        "        imgs_val = X_val[idx]\n",
        "        d_loss_val = discriminator.evaluate(imgs_val, valid, verbose=0)\n",
        "        print(f\"{epoch} [Validation loss: {d_loss_val[0]}, acc.: {100*d_loss_val[1]:.2f}%]\")\n",
        "\n",
        "        # Optionally, save model checkpoints\n",
        "        # generator.save(f'generator_{epoch}.h5')\n",
        "        # discriminator.save(f'discriminator_{epoch}.h5')\n"
      ],
      "metadata": {
        "id": "ChhSiF3mId0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Specify the file path\n",
        "file_path = '/content/drive/MyDrive/SKYSAT_Dataset/20230725_image_data_with_timestamps.csv'\n",
        "\n",
        "# Load the CSV file into a Pandas DataFrame\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the DataFrame or perform further operations\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AnCwJADU90f",
        "outputId": "4be06c1e-8d7b-4caa-a148-6b214df8b483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Unnamed: 0         0         1         2         3         4  \\\n",
            "0  2023-07-25 03:45:00  0.141176  0.141176  0.141176  0.105882  0.105882   \n",
            "1  2023-07-25 03:00:00  0.235294  0.235294  0.235294  0.172549  0.172549   \n",
            "2  2023-07-25 01:30:00  0.200000  0.266667  0.211765  0.094118  0.160784   \n",
            "3  2023-07-25 02:45:00  0.176471  0.176471  0.176471  0.117647  0.117647   \n",
            "4  2023-07-25 00:15:00  0.254902  0.254902  0.254902  0.384314  0.384314   \n",
            "\n",
            "          5         6         7         8  ...    196598    196599    196600  \\\n",
            "0  0.105882  0.254902  0.254902  0.254902  ...  0.352941  0.423529  0.423529   \n",
            "1  0.172549  0.137255  0.137255  0.137255  ...  0.333333  0.568627  0.568627   \n",
            "2  0.105882  0.192157  0.258824  0.203922  ...  0.498039  0.686275  0.717647   \n",
            "3  0.117647  0.133333  0.133333  0.133333  ...  0.388235  0.556863  0.556863   \n",
            "4  0.384314  0.309804  0.309804  0.309804  ...  0.478431  0.694118  0.670588   \n",
            "\n",
            "     196601    196602    196603    196604    196605    196606    196607  \n",
            "0  0.423529  0.458824  0.458824  0.458824  0.388235  0.388235  0.388235  \n",
            "1  0.568627  0.603922  0.603922  0.603922  0.600000  0.600000  0.600000  \n",
            "2  0.678431  0.686275  0.721569  0.682353  0.498039  0.529412  0.490196  \n",
            "3  0.556863  0.627451  0.627451  0.627451  0.643137  0.643137  0.643137  \n",
            "4  0.639216  0.882353  0.870588  0.850980  0.635294  0.635294  0.635294  \n",
            "\n",
            "[5 rows x 196609 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define the folder path where CSV files are located\n",
        "folder_path = '/content/drive/MyDrive/SKYSAT_Dataset'\n",
        "\n",
        "# Get a list of all CSV files in the folder\n",
        "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
        "\n",
        "# Initialize an empty DataFrame to store the merged data\n",
        "merged_df = pd.DataFrame()\n",
        "\n",
        "# Loop through each CSV file\n",
        "for csv_file in csv_files:\n",
        "    # Construct the full file path\n",
        "    file_path = os.path.join(folder_path, csv_file)\n",
        "\n",
        "    # Load the CSV into a Pandas DataFrame\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Rename 'Unnamed: 0' to 'datetime' and convert it to DateTime format\n",
        "    df.rename(columns={'Unnamed: 0': 'datetime'}, inplace=True)\n",
        "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "\n",
        "    # Sort the DataFrame by 'datetime' to maintain temporal order\n",
        "    df.sort_values(by='datetime', inplace=True)\n",
        "\n",
        "    # Append the sorted DataFrame to the merged DataFrame\n",
        "    merged_df = merged_df.append(df, ignore_index=True)\n",
        "\n",
        "# Display the first few rows of the merged DataFrame\n",
        "print(merged_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x24EvpMEVsfA",
        "outputId": "5efddac8-ae22-4414-a0c4-1fdbe8448911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n",
            "<ipython-input-10-c8ab130cbef7>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  merged_df = merged_df.append(df, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             datetime         0         1         2         3         4  \\\n",
            "0 2023-07-25 00:00:00  0.200000  0.266667  0.211765  0.380392  0.447059   \n",
            "1 2023-07-25 00:15:00  0.254902  0.254902  0.254902  0.384314  0.384314   \n",
            "2 2023-07-25 00:30:00  0.258824  0.258824  0.258824  0.321569  0.321569   \n",
            "3 2023-07-25 00:45:00  0.239216  0.239216  0.239216  0.282353  0.282353   \n",
            "4 2023-07-25 01:15:00  0.278431  0.278431  0.278431  0.333333  0.333333   \n",
            "\n",
            "          5         6         7         8  ...    196598    196599    196600  \\\n",
            "0  0.392157  0.403922  0.470588  0.415686  ...  0.482353  0.694118  0.717647   \n",
            "1  0.384314  0.309804  0.309804  0.309804  ...  0.478431  0.694118  0.670588   \n",
            "2  0.321569  0.203922  0.203922  0.203922  ...  0.407843  0.827451  0.827451   \n",
            "3  0.282353  0.270588  0.270588  0.270588  ...  0.725490  0.764706  0.764706   \n",
            "4  0.333333  0.309804  0.309804  0.309804  ...  0.678431  0.556863  0.556863   \n",
            "\n",
            "     196601    196602    196603    196604    196605    196606    196607  \n",
            "0  0.698039  0.756863  0.780392  0.760784  0.733333  0.756863  0.737255  \n",
            "1  0.639216  0.882353  0.870588  0.850980  0.635294  0.635294  0.635294  \n",
            "2  0.827451  0.788235  0.788235  0.788235  0.631373  0.631373  0.631373  \n",
            "3  0.764706  0.631373  0.631373  0.631373  0.666667  0.666667  0.666667  \n",
            "4  0.556863  0.811765  0.811765  0.811765  0.639216  0.639216  0.639216  \n",
            "\n",
            "[5 rows x 196609 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=merged_df\n",
        "# data.to_csv(\"/content/drive/MyDrive/data.csv\")"
      ],
      "metadata": {
        "id": "C7qr-oVfkvpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "FsNAz0Hdz8vD",
        "outputId": "f18e542f-c87e-4166-d909-9e5030278358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                datetime         0         1         2         3         4  \\\n",
              "0    2023-07-25 00:00:00  0.200000  0.266667  0.211765  0.380392  0.447059   \n",
              "1    2023-07-25 00:15:00  0.254902  0.254902  0.254902  0.384314  0.384314   \n",
              "2    2023-07-25 00:30:00  0.258824  0.258824  0.258824  0.321569  0.321569   \n",
              "3    2023-07-25 00:45:00  0.239216  0.239216  0.239216  0.282353  0.282353   \n",
              "4    2023-07-25 01:15:00  0.278431  0.278431  0.278431  0.333333  0.333333   \n",
              "...                  ...       ...       ...       ...       ...       ...   \n",
              "7956 2023-10-02 22:00:00  0.223529  0.223529  0.223529  0.125490  0.125490   \n",
              "7957 2023-10-02 22:15:00  0.239216  0.239216  0.239216  0.129412  0.129412   \n",
              "7958 2023-10-02 22:30:00  0.243137  0.243137  0.243137  0.137255  0.137255   \n",
              "7959 2023-10-02 22:45:00  0.250980  0.250980  0.250980  0.145098  0.145098   \n",
              "7960 2023-10-02 23:00:00  0.247059  0.247059  0.247059  0.149020  0.149020   \n",
              "\n",
              "             5         6         7         8  ...    196598    196599  \\\n",
              "0     0.392157  0.403922  0.470588  0.415686  ...  0.482353  0.694118   \n",
              "1     0.384314  0.309804  0.309804  0.309804  ...  0.478431  0.694118   \n",
              "2     0.321569  0.203922  0.203922  0.203922  ...  0.407843  0.827451   \n",
              "3     0.282353  0.270588  0.270588  0.270588  ...  0.725490  0.764706   \n",
              "4     0.333333  0.309804  0.309804  0.309804  ...  0.678431  0.556863   \n",
              "...        ...       ...       ...       ...  ...       ...       ...   \n",
              "7956  0.125490  0.164706  0.164706  0.164706  ...  0.917647  0.929412   \n",
              "7957  0.129412  0.160784  0.160784  0.160784  ...  0.717647  0.647059   \n",
              "7958  0.137255  0.160784  0.160784  0.160784  ...  0.674510  0.596078   \n",
              "7959  0.145098  0.168627  0.168627  0.168627  ...  0.631373  0.662745   \n",
              "7960  0.149020  0.168627  0.168627  0.168627  ...  0.501961  0.501961   \n",
              "\n",
              "        196600    196601    196602    196603    196604    196605    196606  \\\n",
              "0     0.717647  0.698039  0.756863  0.780392  0.760784  0.733333  0.756863   \n",
              "1     0.670588  0.639216  0.882353  0.870588  0.850980  0.635294  0.635294   \n",
              "2     0.827451  0.827451  0.788235  0.788235  0.788235  0.631373  0.631373   \n",
              "3     0.764706  0.764706  0.631373  0.631373  0.631373  0.666667  0.666667   \n",
              "4     0.556863  0.556863  0.811765  0.811765  0.811765  0.639216  0.639216   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "7956  0.890196  0.898039  0.733333  0.737255  0.737255  0.698039  0.705882   \n",
              "7957  0.647059  0.647059  0.662745  0.662745  0.662745  0.709804  0.709804   \n",
              "7958  0.596078  0.596078  0.694118  0.694118  0.694118  0.823529  0.823529   \n",
              "7959  0.662745  0.662745  0.843137  0.843137  0.843137  0.776471  0.776471   \n",
              "7960  0.501961  0.501961  0.501961  0.501961  0.501961  0.501961  0.501961   \n",
              "\n",
              "        196607  \n",
              "0     0.737255  \n",
              "1     0.635294  \n",
              "2     0.631373  \n",
              "3     0.666667  \n",
              "4     0.639216  \n",
              "...        ...  \n",
              "7956  0.705882  \n",
              "7957  0.709804  \n",
              "7958  0.823529  \n",
              "7959  0.776471  \n",
              "7960  0.501961  \n",
              "\n",
              "[7961 rows x 196609 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8526b19b-e457-4156-b4a1-cd16408d311f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>196598</th>\n",
              "      <th>196599</th>\n",
              "      <th>196600</th>\n",
              "      <th>196601</th>\n",
              "      <th>196602</th>\n",
              "      <th>196603</th>\n",
              "      <th>196604</th>\n",
              "      <th>196605</th>\n",
              "      <th>196606</th>\n",
              "      <th>196607</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-07-25 00:00:00</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.211765</td>\n",
              "      <td>0.380392</td>\n",
              "      <td>0.447059</td>\n",
              "      <td>0.392157</td>\n",
              "      <td>0.403922</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.415686</td>\n",
              "      <td>...</td>\n",
              "      <td>0.482353</td>\n",
              "      <td>0.694118</td>\n",
              "      <td>0.717647</td>\n",
              "      <td>0.698039</td>\n",
              "      <td>0.756863</td>\n",
              "      <td>0.780392</td>\n",
              "      <td>0.760784</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.756863</td>\n",
              "      <td>0.737255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023-07-25 00:15:00</td>\n",
              "      <td>0.254902</td>\n",
              "      <td>0.254902</td>\n",
              "      <td>0.254902</td>\n",
              "      <td>0.384314</td>\n",
              "      <td>0.384314</td>\n",
              "      <td>0.384314</td>\n",
              "      <td>0.309804</td>\n",
              "      <td>0.309804</td>\n",
              "      <td>0.309804</td>\n",
              "      <td>...</td>\n",
              "      <td>0.478431</td>\n",
              "      <td>0.694118</td>\n",
              "      <td>0.670588</td>\n",
              "      <td>0.639216</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>0.870588</td>\n",
              "      <td>0.850980</td>\n",
              "      <td>0.635294</td>\n",
              "      <td>0.635294</td>\n",
              "      <td>0.635294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023-07-25 00:30:00</td>\n",
              "      <td>0.258824</td>\n",
              "      <td>0.258824</td>\n",
              "      <td>0.258824</td>\n",
              "      <td>0.321569</td>\n",
              "      <td>0.321569</td>\n",
              "      <td>0.321569</td>\n",
              "      <td>0.203922</td>\n",
              "      <td>0.203922</td>\n",
              "      <td>0.203922</td>\n",
              "      <td>...</td>\n",
              "      <td>0.407843</td>\n",
              "      <td>0.827451</td>\n",
              "      <td>0.827451</td>\n",
              "      <td>0.827451</td>\n",
              "      <td>0.788235</td>\n",
              "      <td>0.788235</td>\n",
              "      <td>0.788235</td>\n",
              "      <td>0.631373</td>\n",
              "      <td>0.631373</td>\n",
              "      <td>0.631373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023-07-25 00:45:00</td>\n",
              "      <td>0.239216</td>\n",
              "      <td>0.239216</td>\n",
              "      <td>0.239216</td>\n",
              "      <td>0.282353</td>\n",
              "      <td>0.282353</td>\n",
              "      <td>0.282353</td>\n",
              "      <td>0.270588</td>\n",
              "      <td>0.270588</td>\n",
              "      <td>0.270588</td>\n",
              "      <td>...</td>\n",
              "      <td>0.725490</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.631373</td>\n",
              "      <td>0.631373</td>\n",
              "      <td>0.631373</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023-07-25 01:15:00</td>\n",
              "      <td>0.278431</td>\n",
              "      <td>0.278431</td>\n",
              "      <td>0.278431</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.309804</td>\n",
              "      <td>0.309804</td>\n",
              "      <td>0.309804</td>\n",
              "      <td>...</td>\n",
              "      <td>0.678431</td>\n",
              "      <td>0.556863</td>\n",
              "      <td>0.556863</td>\n",
              "      <td>0.556863</td>\n",
              "      <td>0.811765</td>\n",
              "      <td>0.811765</td>\n",
              "      <td>0.811765</td>\n",
              "      <td>0.639216</td>\n",
              "      <td>0.639216</td>\n",
              "      <td>0.639216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7956</th>\n",
              "      <td>2023-10-02 22:00:00</td>\n",
              "      <td>0.223529</td>\n",
              "      <td>0.223529</td>\n",
              "      <td>0.223529</td>\n",
              "      <td>0.125490</td>\n",
              "      <td>0.125490</td>\n",
              "      <td>0.125490</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>...</td>\n",
              "      <td>0.917647</td>\n",
              "      <td>0.929412</td>\n",
              "      <td>0.890196</td>\n",
              "      <td>0.898039</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.737255</td>\n",
              "      <td>0.737255</td>\n",
              "      <td>0.698039</td>\n",
              "      <td>0.705882</td>\n",
              "      <td>0.705882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7957</th>\n",
              "      <td>2023-10-02 22:15:00</td>\n",
              "      <td>0.239216</td>\n",
              "      <td>0.239216</td>\n",
              "      <td>0.239216</td>\n",
              "      <td>0.129412</td>\n",
              "      <td>0.129412</td>\n",
              "      <td>0.129412</td>\n",
              "      <td>0.160784</td>\n",
              "      <td>0.160784</td>\n",
              "      <td>0.160784</td>\n",
              "      <td>...</td>\n",
              "      <td>0.717647</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.662745</td>\n",
              "      <td>0.662745</td>\n",
              "      <td>0.662745</td>\n",
              "      <td>0.709804</td>\n",
              "      <td>0.709804</td>\n",
              "      <td>0.709804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7958</th>\n",
              "      <td>2023-10-02 22:30:00</td>\n",
              "      <td>0.243137</td>\n",
              "      <td>0.243137</td>\n",
              "      <td>0.243137</td>\n",
              "      <td>0.137255</td>\n",
              "      <td>0.137255</td>\n",
              "      <td>0.137255</td>\n",
              "      <td>0.160784</td>\n",
              "      <td>0.160784</td>\n",
              "      <td>0.160784</td>\n",
              "      <td>...</td>\n",
              "      <td>0.674510</td>\n",
              "      <td>0.596078</td>\n",
              "      <td>0.596078</td>\n",
              "      <td>0.596078</td>\n",
              "      <td>0.694118</td>\n",
              "      <td>0.694118</td>\n",
              "      <td>0.694118</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>0.823529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7959</th>\n",
              "      <td>2023-10-02 22:45:00</td>\n",
              "      <td>0.250980</td>\n",
              "      <td>0.250980</td>\n",
              "      <td>0.250980</td>\n",
              "      <td>0.145098</td>\n",
              "      <td>0.145098</td>\n",
              "      <td>0.145098</td>\n",
              "      <td>0.168627</td>\n",
              "      <td>0.168627</td>\n",
              "      <td>0.168627</td>\n",
              "      <td>...</td>\n",
              "      <td>0.631373</td>\n",
              "      <td>0.662745</td>\n",
              "      <td>0.662745</td>\n",
              "      <td>0.662745</td>\n",
              "      <td>0.843137</td>\n",
              "      <td>0.843137</td>\n",
              "      <td>0.843137</td>\n",
              "      <td>0.776471</td>\n",
              "      <td>0.776471</td>\n",
              "      <td>0.776471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7960</th>\n",
              "      <td>2023-10-02 23:00:00</td>\n",
              "      <td>0.247059</td>\n",
              "      <td>0.247059</td>\n",
              "      <td>0.247059</td>\n",
              "      <td>0.149020</td>\n",
              "      <td>0.149020</td>\n",
              "      <td>0.149020</td>\n",
              "      <td>0.168627</td>\n",
              "      <td>0.168627</td>\n",
              "      <td>0.168627</td>\n",
              "      <td>...</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.501961</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7961 rows × 196609 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8526b19b-e457-4156-b4a1-cd16408d311f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8526b19b-e457-4156-b4a1-cd16408d311f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8526b19b-e457-4156-b4a1-cd16408d311f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fd805eaf-912e-4b91-bbd6-eb75fa3eacd0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fd805eaf-912e-4b91-bbd6-eb75fa3eacd0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fd805eaf-912e-4b91-bbd6-eb75fa3eacd0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_1d544615-7524-48af-91ff-e9f691095177\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('merged_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1d544615-7524-48af-91ff-e9f691095177 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('merged_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.set_index('datetime')"
      ],
      "metadata": {
        "id": "kJeB9FP_7sb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "id": "jsG2TyBf7wll",
        "outputId": "19eaa488-dee0-467b-8e57-44f59da8e9fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            0         1         2         3         4  \\\n",
              "datetime                                                                \n",
              "2023-07-25 00:00:00  0.200000  0.266667  0.211765  0.380392  0.447059   \n",
              "2023-07-25 00:15:00  0.254902  0.254902  0.254902  0.384314  0.384314   \n",
              "2023-07-25 00:30:00  0.258824  0.258824  0.258824  0.321569  0.321569   \n",
              "2023-07-25 00:45:00  0.239216  0.239216  0.239216  0.282353  0.282353   \n",
              "2023-07-25 01:15:00  0.278431  0.278431  0.278431  0.333333  0.333333   \n",
              "...                       ...       ...       ...       ...       ...   \n",
              "2023-12-12 22:30:00  0.388235  0.388235  0.388235  0.290196  0.290196   \n",
              "2023-12-12 23:00:00  0.388235  0.388235  0.388235  0.290196  0.290196   \n",
              "2023-12-12 23:15:00  0.403922  0.403922  0.403922  0.305882  0.305882   \n",
              "2023-12-12 23:30:00  0.380392  0.380392  0.380392  0.286275  0.286275   \n",
              "2023-12-12 23:45:00  0.388235  0.388235  0.388235  0.278431  0.278431   \n",
              "\n",
              "                            5         6         7         8         9  ...  \\\n",
              "datetime                                                               ...   \n",
              "2023-07-25 00:00:00  0.392157  0.403922  0.470588  0.415686  0.392157  ...   \n",
              "2023-07-25 00:15:00  0.384314  0.309804  0.309804  0.309804  0.427451  ...   \n",
              "2023-07-25 00:30:00  0.321569  0.203922  0.203922  0.203922  0.462745  ...   \n",
              "2023-07-25 00:45:00  0.282353  0.270588  0.270588  0.270588  0.427451  ...   \n",
              "2023-07-25 01:15:00  0.333333  0.309804  0.309804  0.309804  0.423529  ...   \n",
              "...                       ...       ...       ...       ...       ...  ...   \n",
              "2023-12-12 22:30:00  0.290196  0.325490  0.325490  0.325490  0.376471  ...   \n",
              "2023-12-12 23:00:00  0.290196  0.333333  0.333333  0.333333  0.388235  ...   \n",
              "2023-12-12 23:15:00  0.305882  0.329412  0.329412  0.329412  0.380392  ...   \n",
              "2023-12-12 23:30:00  0.286275  0.329412  0.329412  0.329412  0.380392  ...   \n",
              "2023-12-12 23:45:00  0.278431  0.329412  0.329412  0.329412  0.380392  ...   \n",
              "\n",
              "                       196598    196599    196600    196601    196602  \\\n",
              "datetime                                                                \n",
              "2023-07-25 00:00:00  0.482353  0.694118  0.717647  0.698039  0.756863   \n",
              "2023-07-25 00:15:00  0.478431  0.694118  0.670588  0.639216  0.882353   \n",
              "2023-07-25 00:30:00  0.407843  0.827451  0.827451  0.827451  0.788235   \n",
              "2023-07-25 00:45:00  0.725490  0.764706  0.764706  0.764706  0.631373   \n",
              "2023-07-25 01:15:00  0.678431  0.556863  0.556863  0.556863  0.811765   \n",
              "...                       ...       ...       ...       ...       ...   \n",
              "2023-12-12 22:30:00  0.298039  0.403922  0.403922  0.403922  0.447059   \n",
              "2023-12-12 23:00:00  0.396078  0.423529  0.423529  0.423529  0.435294   \n",
              "2023-12-12 23:15:00  0.368627  0.372549  0.372549  0.372549  0.415686   \n",
              "2023-12-12 23:30:00  0.345098  0.376471  0.376471  0.376471  0.392157   \n",
              "2023-12-12 23:45:00  0.352941  0.380392  0.380392  0.380392  0.372549   \n",
              "\n",
              "                       196603    196604    196605    196606    196607  \n",
              "datetime                                                               \n",
              "2023-07-25 00:00:00  0.780392  0.760784  0.733333  0.756863  0.737255  \n",
              "2023-07-25 00:15:00  0.870588  0.850980  0.635294  0.635294  0.635294  \n",
              "2023-07-25 00:30:00  0.788235  0.788235  0.631373  0.631373  0.631373  \n",
              "2023-07-25 00:45:00  0.631373  0.631373  0.666667  0.666667  0.666667  \n",
              "2023-07-25 01:15:00  0.811765  0.811765  0.639216  0.639216  0.639216  \n",
              "...                       ...       ...       ...       ...       ...  \n",
              "2023-12-12 22:30:00  0.447059  0.447059  0.400000  0.400000  0.400000  \n",
              "2023-12-12 23:00:00  0.435294  0.435294  0.403922  0.403922  0.403922  \n",
              "2023-12-12 23:15:00  0.415686  0.415686  0.470588  0.470588  0.470588  \n",
              "2023-12-12 23:30:00  0.392157  0.392157  0.376471  0.376471  0.376471  \n",
              "2023-12-12 23:45:00  0.372549  0.372549  0.313725  0.313725  0.313725  \n",
              "\n",
              "[7961 rows x 196608 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f92e62bc-3cd7-4a58-afe5-4d2f7e4842db\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>196598</th>\n",
              "      <th>196599</th>\n",
              "      <th>196600</th>\n",
              "      <th>196601</th>\n",
              "      <th>196602</th>\n",
              "      <th>196603</th>\n",
              "      <th>196604</th>\n",
              "      <th>196605</th>\n",
              "      <th>196606</th>\n",
              "      <th>196607</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-07-25 00:00:00</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.211765</td>\n",
              "      <td>0.380392</td>\n",
              "      <td>0.447059</td>\n",
              "      <td>0.392157</td>\n",
              "      <td>0.403922</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.415686</td>\n",
              "      <td>0.392157</td>\n",
              "      <td>...</td>\n",
              "      <td>0.482353</td>\n",
              "      <td>0.694118</td>\n",
              "      <td>0.717647</td>\n",
              "      <td>0.698039</td>\n",
              "      <td>0.756863</td>\n",
              "      <td>0.780392</td>\n",
              "      <td>0.760784</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.756863</td>\n",
              "      <td>0.737255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-25 00:15:00</th>\n",
              "      <td>0.254902</td>\n",
              "      <td>0.254902</td>\n",
              "      <td>0.254902</td>\n",
              "      <td>0.384314</td>\n",
              "      <td>0.384314</td>\n",
              "      <td>0.384314</td>\n",
              "      <td>0.309804</td>\n",
              "      <td>0.309804</td>\n",
              "      <td>0.309804</td>\n",
              "      <td>0.427451</td>\n",
              "      <td>...</td>\n",
              "      <td>0.478431</td>\n",
              "      <td>0.694118</td>\n",
              "      <td>0.670588</td>\n",
              "      <td>0.639216</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>0.870588</td>\n",
              "      <td>0.850980</td>\n",
              "      <td>0.635294</td>\n",
              "      <td>0.635294</td>\n",
              "      <td>0.635294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-25 00:30:00</th>\n",
              "      <td>0.258824</td>\n",
              "      <td>0.258824</td>\n",
              "      <td>0.258824</td>\n",
              "      <td>0.321569</td>\n",
              "      <td>0.321569</td>\n",
              "      <td>0.321569</td>\n",
              "      <td>0.203922</td>\n",
              "      <td>0.203922</td>\n",
              "      <td>0.203922</td>\n",
              "      <td>0.462745</td>\n",
              "      <td>...</td>\n",
              "      <td>0.407843</td>\n",
              "      <td>0.827451</td>\n",
              "      <td>0.827451</td>\n",
              "      <td>0.827451</td>\n",
              "      <td>0.788235</td>\n",
              "      <td>0.788235</td>\n",
              "      <td>0.788235</td>\n",
              "      <td>0.631373</td>\n",
              "      <td>0.631373</td>\n",
              "      <td>0.631373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-25 00:45:00</th>\n",
              "      <td>0.239216</td>\n",
              "      <td>0.239216</td>\n",
              "      <td>0.239216</td>\n",
              "      <td>0.282353</td>\n",
              "      <td>0.282353</td>\n",
              "      <td>0.282353</td>\n",
              "      <td>0.270588</td>\n",
              "      <td>0.270588</td>\n",
              "      <td>0.270588</td>\n",
              "      <td>0.427451</td>\n",
              "      <td>...</td>\n",
              "      <td>0.725490</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.631373</td>\n",
              "      <td>0.631373</td>\n",
              "      <td>0.631373</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-25 01:15:00</th>\n",
              "      <td>0.278431</td>\n",
              "      <td>0.278431</td>\n",
              "      <td>0.278431</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.309804</td>\n",
              "      <td>0.309804</td>\n",
              "      <td>0.309804</td>\n",
              "      <td>0.423529</td>\n",
              "      <td>...</td>\n",
              "      <td>0.678431</td>\n",
              "      <td>0.556863</td>\n",
              "      <td>0.556863</td>\n",
              "      <td>0.556863</td>\n",
              "      <td>0.811765</td>\n",
              "      <td>0.811765</td>\n",
              "      <td>0.811765</td>\n",
              "      <td>0.639216</td>\n",
              "      <td>0.639216</td>\n",
              "      <td>0.639216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-12-12 22:30:00</th>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>0.325490</td>\n",
              "      <td>0.325490</td>\n",
              "      <td>0.325490</td>\n",
              "      <td>0.376471</td>\n",
              "      <td>...</td>\n",
              "      <td>0.298039</td>\n",
              "      <td>0.403922</td>\n",
              "      <td>0.403922</td>\n",
              "      <td>0.403922</td>\n",
              "      <td>0.447059</td>\n",
              "      <td>0.447059</td>\n",
              "      <td>0.447059</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-12-12 23:00:00</th>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>...</td>\n",
              "      <td>0.396078</td>\n",
              "      <td>0.423529</td>\n",
              "      <td>0.423529</td>\n",
              "      <td>0.423529</td>\n",
              "      <td>0.435294</td>\n",
              "      <td>0.435294</td>\n",
              "      <td>0.435294</td>\n",
              "      <td>0.403922</td>\n",
              "      <td>0.403922</td>\n",
              "      <td>0.403922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-12-12 23:15:00</th>\n",
              "      <td>0.403922</td>\n",
              "      <td>0.403922</td>\n",
              "      <td>0.403922</td>\n",
              "      <td>0.305882</td>\n",
              "      <td>0.305882</td>\n",
              "      <td>0.305882</td>\n",
              "      <td>0.329412</td>\n",
              "      <td>0.329412</td>\n",
              "      <td>0.329412</td>\n",
              "      <td>0.380392</td>\n",
              "      <td>...</td>\n",
              "      <td>0.368627</td>\n",
              "      <td>0.372549</td>\n",
              "      <td>0.372549</td>\n",
              "      <td>0.372549</td>\n",
              "      <td>0.415686</td>\n",
              "      <td>0.415686</td>\n",
              "      <td>0.415686</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.470588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-12-12 23:30:00</th>\n",
              "      <td>0.380392</td>\n",
              "      <td>0.380392</td>\n",
              "      <td>0.380392</td>\n",
              "      <td>0.286275</td>\n",
              "      <td>0.286275</td>\n",
              "      <td>0.286275</td>\n",
              "      <td>0.329412</td>\n",
              "      <td>0.329412</td>\n",
              "      <td>0.329412</td>\n",
              "      <td>0.380392</td>\n",
              "      <td>...</td>\n",
              "      <td>0.345098</td>\n",
              "      <td>0.376471</td>\n",
              "      <td>0.376471</td>\n",
              "      <td>0.376471</td>\n",
              "      <td>0.392157</td>\n",
              "      <td>0.392157</td>\n",
              "      <td>0.392157</td>\n",
              "      <td>0.376471</td>\n",
              "      <td>0.376471</td>\n",
              "      <td>0.376471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-12-12 23:45:00</th>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.278431</td>\n",
              "      <td>0.278431</td>\n",
              "      <td>0.278431</td>\n",
              "      <td>0.329412</td>\n",
              "      <td>0.329412</td>\n",
              "      <td>0.329412</td>\n",
              "      <td>0.380392</td>\n",
              "      <td>...</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.380392</td>\n",
              "      <td>0.380392</td>\n",
              "      <td>0.380392</td>\n",
              "      <td>0.372549</td>\n",
              "      <td>0.372549</td>\n",
              "      <td>0.372549</td>\n",
              "      <td>0.313725</td>\n",
              "      <td>0.313725</td>\n",
              "      <td>0.313725</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7961 rows × 196608 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f92e62bc-3cd7-4a58-afe5-4d2f7e4842db')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f92e62bc-3cd7-4a58-afe5-4d2f7e4842db button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f92e62bc-3cd7-4a58-afe5-4d2f7e4842db');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-23a0bb09-d5b4-4866-becb-9463d9e76c68\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-23a0bb09-d5b4-4866-becb-9463d9e76c68')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-23a0bb09-d5b4-4866-becb-9463d9e76c68 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6f96860c-8bc6-489f-b065-90cc3f5bf85c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6f96860c-8bc6-489f-b065-90cc3f5bf85c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load your data\n",
        "# data = pd.read_csv('your_dataset.csv')  # Assuming you've done this step\n",
        "\n",
        "# Sort the data by 'datetime' to ensure temporal order\n",
        "data = data.sort_values(by='datetime', ascending=True)\n",
        "\n",
        "# Calculate sizes for train, validation, and test sets\n",
        "train_ratio = 0.8\n",
        "validation_ratio = 0.2\n",
        "train_size = int(train_ratio * len(data))\n",
        "validation_size = int(validation_ratio * train_size)\n",
        "\n",
        "# Split the data\n",
        "train_data = data.iloc[:train_size]\n",
        "test_data = data.iloc[train_size:]\n",
        "\n",
        "# Further split the train_data into training and validation sets\n",
        "validation_data = train_data.iloc[:validation_size]\n",
        "train_data = train_data.iloc[validation_size:]\n",
        "\n",
        "# At this point, you need to ensure your model can handle the data format.\n",
        "# Specifically, if these are image data, reshape or preprocess them as needed.\n"
      ],
      "metadata": {
        "id": "nBqyAF3VkgsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming train_data, validation_data, and test_data are your datasets\n",
        "\n",
        "# Print the shape of each dataset\n",
        "print(\"Training data shape:\", train_data.shape)\n",
        "print(\"Validation data shape:\", validation_data.shape)\n",
        "print(\"Test data shape:\", test_data.shape)\n",
        "\n",
        "# Example of a normalization check (adapt based on your actual preprocessing)\n",
        "# Here, we check if the first element is normalized\n",
        "print(\"Sample pixel values in training data:\", train_data.iloc[0, 1:10])  # Adjust indexing based on your data structure\n",
        "\n",
        "# Check for the maximum and minimum values, which helps to understand the normalization scale\n",
        "print(\"Max pixel value in training data:\", train_data.iloc[:, 1:].max().max())  # Adjust slicing as per your dataset structure\n",
        "print(\"Min pixel value in training data:\", train_data.iloc[:, 1:].min().min())\n",
        "\n",
        "# If reshaping is necessary (e.g., for CNNs), this is how you might begin to approach it:\n",
        "# Note: This is a pseudo-code line to indicate reshaping, replace it with your actual reshaping code if needed\n",
        "# print(\"Reshaped training data for model input:\", train_data_reshaped.shape)\n",
        "\n",
        "# Add any additional checks specific to your model or data preprocessing needs here\n",
        "# For example, checking the distribution of labels if it's a classification problem\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3AXJpAm4iTi",
        "outputId": "0526347a-99f0-47ce-dfe3-7f01270aaa85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (5095, 196608)\n",
            "Validation data shape: (1273, 196608)\n",
            "Test data shape: (1593, 196608)\n",
            "Sample pixel values in training data: 1    0.168627\n",
            "2    0.168627\n",
            "3    0.121569\n",
            "4    0.121569\n",
            "5    0.121569\n",
            "6    0.141176\n",
            "7    0.141176\n",
            "8    0.141176\n",
            "9    0.145098\n",
            "Name: 2023-08-16 09:15:00, dtype: float64\n",
            "Max pixel value in training data: 1.0\n",
            "Min pixel value in training data: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_encoder(input_shape, num_transformer_layers=4, num_heads=8, dff=2048, patch_size=16):\n",
        "    num_patches = (input_shape[0] // patch_size) * (input_shape[1] // patch_size)\n",
        "    patch_dim = patch_size * patch_size * input_shape[2]\n",
        "\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "\n",
        "    # Extract patches\n",
        "    patches = tf.image.extract_patches(\n",
        "        images=inputs,\n",
        "        sizes=[1, patch_size, patch_size, 1],\n",
        "        strides=[1, patch_size, patch_size, 1],\n",
        "        rates=[1, 1, 1, 1],\n",
        "        padding='VALID',\n",
        "    )\n",
        "    # Flatten the patches\n",
        "    patches = tf.reshape(patches, [-1, num_patches, patch_dim])\n",
        "\n",
        "    # Create patch encodings\n",
        "    patch_encoder = layers.Embedding(input_dim=num_patches, output_dim=patch_dim)\n",
        "    positional_encodings = patch_encoder(tf.range(num_patches))\n",
        "\n",
        "    # Add positional encodings to patches\n",
        "    x = patches + positional_encodings\n",
        "\n",
        "    for _ in range(num_transformer_layers):\n",
        "        x = layers.MultiHeadAttention(num_heads=num_heads, key_dim=patch_dim // num_heads)(x, x)\n",
        "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        # Feed Forward Network\n",
        "        x = layers.Dense(dff, activation='relu')(x)\n",
        "        x = layers.Dense(patch_dim)(x)\n",
        "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "    encoder_model = Model(inputs, x, name='encoder')\n",
        "    return encoder_model\n",
        "\n",
        "encoder_input_shape = (256, 256, 3)\n",
        "encoder = build_encoder(encoder_input_shape)\n"
      ],
      "metadata": {
        "id": "QvepIbQ4kyoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_decoder(input_shape, num_transformer_layers=4, num_heads=8, dff=2048, patch_size=16):\n",
        "    # Calculate the number of patches and the dimension of each flattened patch\n",
        "    num_patches = (input_shape[0] // patch_size) * (input_shape[1] // patch_size)\n",
        "    patch_dim = patch_size * patch_size * input_shape[2]\n",
        "\n",
        "    # The input shape will be the number of patches and the dimension of each patch\n",
        "    encoded_patches_shape = (num_patches, patch_dim)\n",
        "    inputs = tf.keras.layers.Input(shape=encoded_patches_shape)\n",
        "\n",
        "    # Create patch encodings\n",
        "    patch_encoder = layers.Embedding(input_dim=num_patches, output_dim=patch_dim)\n",
        "    positional_encodings = patch_encoder(tf.range(num_patches))\n",
        "\n",
        "    # Add positional encodings to the encoded patches\n",
        "    x = inputs + positional_encodings\n",
        "\n",
        "    for _ in range(num_transformer_layers):\n",
        "        x = layers.MultiHeadAttention(num_heads=num_heads, key_dim=patch_dim // num_heads)(x, x)\n",
        "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        # Feed Forward Network\n",
        "        x = layers.Dense(dff, activation='relu')(x)\n",
        "        x = layers.Dense(patch_dim)(x)\n",
        "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "    # Reshape the output to reconstruct the image\n",
        "    # The shape of the output should be the original image dimensions (height, width, channels)\n",
        "    reconstructed_image = layers.Dense(input_shape[0] * input_shape[1] * input_shape[2], activation='sigmoid')(x)\n",
        "    reconstructed_image = tf.reshape(reconstructed_image, (-1, input_shape[0], input_shape[1], input_shape[2]))\n",
        "\n",
        "    decoder_model = Model(inputs, reconstructed_image, name='decoder')\n",
        "    return decoder_model\n",
        "\n",
        "# Use the same input shape as the encoder\n",
        "decoder = build_decoder(encoder_input_shape)\n"
      ],
      "metadata": {
        "id": "HzDviti8k3wN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "    predictions = model(test_input, training=False)\n",
        "\n",
        "    # If your model outputs flattened data, you need to reshape it back to the image format\n",
        "    predictions = tf.reshape(predictions, (-1, image_height, image_width, num_channels))  # Replace with actual dimensions\n",
        "\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        plt.imshow(predictions[i, :, :, :])\n",
        "        plt.axis('off')\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "OJDYAdP1-Ww8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "num_epochs = 100\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "wW6e8n_g66mZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_loss(y_true, y_pred, y_true_next=None):\n",
        "    print(\"y_true shape:\", y_true.shape)\n",
        "    print(\"y_pred shape:\", y_pred.shape)\n",
        "    if y_true_next is not None:\n",
        "        print(\"y_true_next shape:\", y_true_next.shape)\n",
        "\n",
        "    # Compute image reconstruction loss as before\n",
        "    image_reconstruction_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "\n",
        "    # Compute temporal consistency loss\n",
        "    temporal_consistency_loss = 0\n",
        "    if y_true_next is not None:\n",
        "        temporal_consistency_loss = tf.reduce_mean(tf.square(y_pred - y_true_next))\n",
        "\n",
        "    alpha = 0.8\n",
        "    # Combine the losses with the weighting factor\n",
        "    total_loss = alpha * image_reconstruction_loss + (1 - alpha) * temporal_consistency_loss\n",
        "    return total_loss\n",
        "\n"
      ],
      "metadata": {
        "id": "LMEJckyHk8ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    num_batches = (len(train_data) - batch_size) // batch_size  # Calculate the number of batches\n",
        "\n",
        "    # Iterate over the training data in batches\n",
        "    for i in range(0, len(train_data) - batch_size, batch_size):\n",
        "        batch_data = train_data[i:i+batch_size]\n",
        "        batch_data_next = train_data[i+1:i+1+batch_size] if i + 1 + batch_size <= len(train_data) else None\n",
        "\n",
        "        # Reshape data\n",
        "        batch_data_reshaped = tf.reshape(batch_data, (-1, 256, 256, 3))\n",
        "        batch_data_next_reshaped = tf.reshape(batch_data_next, (-1, 256, 256, 3)) if batch_data_next is not None else None\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Generate predictions for the current batch\n",
        "            reconstructed_images = decoder(encoder(batch_data_reshaped))\n",
        "            # Compute the custom loss using the current batch and the next batch, if available\n",
        "            loss = custom_loss(batch_data_reshaped, reconstructed_images, batch_data_next_reshaped)\n",
        "\n",
        "        gradients = tape.gradient(loss, decoder.trainable_variables + encoder.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, decoder.trainable_variables + encoder.trainable_variables))\n",
        "        total_loss += loss.numpy()\n",
        "\n",
        "    average_loss = total_loss / num_batches  # Divide by the number of batches\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss:.4f}')\n",
        "    # Additional steps like validation and generating images can follow here, with proper indentation."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "00cM9wjFDaI2",
        "outputId": "2803dc4c-102a-4f05-b682-2685c5d4d9fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "Exception encountered when calling layer 'dense_32' (type Dense).\n\n{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[4096,196608] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:MatMul] name: \n\nCall arguments received by layer 'dense_32' (type Dense):\n  • inputs=tf.Tensor(shape=(16, 256, 768), dtype=float32)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-1ba74b62aa53>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# Generate predictions for the current batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mreconstructed_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;31m# Compute the custom loss using the current batch and the next batch, if available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructed_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data_next_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5882\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5883\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer 'dense_32' (type Dense).\n\n{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[4096,196608] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:MatMul] name: \n\nCall arguments received by layer 'dense_32' (type Dense):\n  • inputs=tf.Tensor(shape=(16, 256, 768), dtype=float32)"
          ]
        }
      ]
    }
  ]
}